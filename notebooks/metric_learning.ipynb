{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T10:08:41.570104Z",
     "start_time": "2019-11-03T10:08:41.565249Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/landmark/experiments/deep-image-retrieval/')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T10:11:24.336464Z",
     "start_time": "2019-11-03T10:11:16.969202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> loaded network: \n",
      "  (meta): dict( \n",
      "     architecture: resnet101\n",
      "     local_whitening: False\n",
      "     pooling: gem\n",
      "     regional: False\n",
      "     whitening: True\n",
      "     outputdim: 2048\n",
      "     mean: [0.485, 0.456, 0.406]\n",
      "     std: [0.229, 0.224, 0.225]\n",
      "  )\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ImageRetrievalNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (6): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (7): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (8): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (9): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (10): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (11): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (12): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (13): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (14): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (15): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (16): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (17): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (18): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (19): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (20): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (21): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (22): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pool): GeM(p=2.8640, eps=1e-06)\n",
       "  (whiten): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "  (norm): L2N(eps=1e-06)\n",
       "  (meta): dict( \n",
       "     architecture: resnet101\n",
       "     local_whitening: False\n",
       "     pooling: gem\n",
       "     regional: False\n",
       "     whitening: True\n",
       "     outputdim: 2048\n",
       "     mean: [0.485, 0.456, 0.406]\n",
       "     std: [0.229, 0.224, 0.225]\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.nn import Parameter\n",
    "from torch.utils.model_zoo import load_url\n",
    "from torchvision import transforms\n",
    "\n",
    "from cirtorch.networks.imageretrievalnet import init_network, extract_vectors\n",
    "from cirtorch.datasets.testdataset import configdataset\n",
    "from cirtorch.utils.download import download_train, download_test\n",
    "from cirtorch.utils.evaluate import compute_map_and_print\n",
    "from cirtorch.utils.general import get_data_root, htime\n",
    "\n",
    "PRETRAINED = {\n",
    "    'rSfM120k-tl-resnet50-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/rSfM120k-tl-resnet50-gem-w-97bf910.pth',\n",
    "    'rSfM120k-tl-resnet101-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/rSfM120k-tl-resnet101-gem-w-a155e54.pth',\n",
    "    'rSfM120k-tl-resnet152-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/retrieval-SfM-120k/rSfM120k-tl-resnet152-gem-w-f39cada.pth',\n",
    "    'gl18-tl-resnet50-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/gl18/gl18-tl-resnet50-gem-w-83fdc30.pth',\n",
    "    'gl18-tl-resnet101-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/gl18/gl18-tl-resnet101-gem-w-a4d43db.pth',\n",
    "    'gl18-tl-resnet152-gem-w': 'http://cmp.felk.cvut.cz/cnnimageretrieval/data/networks/gl18/gl18-tl-resnet152-gem-w-21278d5.pth',\n",
    "}\n",
    "\n",
    "# datasets_names = ['oxford5k', 'paris6k', 'roxford5k', 'rparis6k']\n",
    "datasets_names = ['roxford5k', 'rparis6k']\n",
    "\n",
    "state = load_url(PRETRAINED['gl18-tl-resnet101-gem-w'], model_dir=os.path.join(\n",
    "    get_data_root(), 'networks'))\n",
    "\n",
    "net_params = {}\n",
    "net_params['architecture'] = state['meta']['architecture']\n",
    "net_params['pooling'] = state['meta']['pooling']\n",
    "net_params['local_whitening'] = state['meta'].get('local_whitening', False)\n",
    "net_params['regional'] = state['meta'].get('regional', False)\n",
    "net_params['whitening'] = state['meta'].get('whitening', False)\n",
    "net_params['mean'] = state['meta']['mean']\n",
    "net_params['std'] = state['meta']['std']\n",
    "net_params['pretrained'] = False\n",
    "# network initialization\n",
    "net = init_network(net_params)\n",
    "net.pool.p = Parameter(torch.ones(1) * 3.0)\n",
    "net.load_state_dict(state['state_dict'])\n",
    "\n",
    "print(\">>>> loaded network: \")\n",
    "print(net.meta_repr())\n",
    "\n",
    "# moving network to gpu and eval mode\n",
    "net.cuda()\n",
    "net.eval()\n",
    "model = net\n",
    "model.extract_feat = lambda x: model(x).t()\n",
    "model.DIVIDABLE_BY = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T10:34:36.917715Z",
     "start_time": "2019-11-03T10:17:03.411225Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "roxford5k: 100%|███| 4993/4993 [07:42<00:00, 10.90it/s]\n",
      "roxford5k: 100%|███████| 70/70 [00:04<00:00, 14.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> roxford5k: mAP E: 84.37, M: 67.22, H: 43.61\n",
      ">> roxford5k: mP@k[1, 5, 10] E: [94.12 90.29 86.99], M: [94.29 90.   84.86], H: [87.14 69.14 59.43]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rparis6k: 100%|████| 6322/6322 [09:39<00:00, 10.92it/s]\n",
      "rparis6k: 100%|████████| 70/70 [00:04<00:00, 14.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: mAP E: 92.94, M: 80.62, H: 61.39\n",
      ">> rparis6k: mP@k[1, 5, 10] E: [98.57 96.57 95.29], M: [100.    98.    96.86], H: [97.14 93.43 91.14]\n"
     ]
    }
   ],
   "source": [
    "from src.eval_retrieval import eval_datasets\n",
    "datasets = ('roxford5k', 'rparis6k')\n",
    "results = eval_datasets(model, datasets=datasets, ms=True, tta_gem_p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-03T15:25:49.251Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|██████▉       | 3655/7351 [43:28<47:14,  1.30it/s]"
     ]
    }
   ],
   "source": [
    "from src import utils, data_utils, metrics\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "ROOT = '/opt/landmark/'\n",
    "params = {\n",
    "    'ex_name': 'eval_triplet',\n",
    "    'test_batch_size': 16,\n",
    "    'fc_dim': 2048,\n",
    "}\n",
    "splits = ['test19', 'index19']\n",
    "scale = 'L2'\n",
    "ms = True\n",
    "n_blocks = 1\n",
    "block_id = 0\n",
    "\n",
    "train_transform, eval_transform = data_utils.build_transforms()\n",
    "\n",
    "data_loaders = data_utils.make_predict_loaders(params,\n",
    "                                               eval_transform=eval_transform,\n",
    "                                               scale=scale,\n",
    "                                               splits=splits,\n",
    "                                               num_workers=8,\n",
    "                                               n_blocks=n_blocks,\n",
    "                                               block_id=block_id)\n",
    "\n",
    "model_path = ROOT + '../data/networks/gl18-tl-resnet101-gem-w-a4d43db.pth'\n",
    "exp_path = ROOT + f'experiments/{params[\"ex_name\"]}/'\n",
    "if not Path(exp_path).exists():\n",
    "    Path(exp_path).mkdir(parents=True)\n",
    "\n",
    "file_suffix = model_path.split('/')[-1].replace('.pth', '')\n",
    "file_suffix = scale + '_' + file_suffix\n",
    "file_suffix = 'ms_' + file_suffix if ms else file_suffix\n",
    "\n",
    "min_size = 128\n",
    "scales = [0.75, 1.0, 1.25] if ms else [1.0]\n",
    "\n",
    "for split in splits:\n",
    "    ids, feats = [], []\n",
    "    for i, (img_id, x) in tqdm(enumerate(data_loaders[split]),\n",
    "                               total=len(data_loaders[split]),\n",
    "                               miniters=None, ncols=55):\n",
    "\n",
    "        batch_size, _, h, w = x.shape\n",
    "        feat_blend = np.zeros((batch_size, params['fc_dim']), dtype=np.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to('cuda')\n",
    "\n",
    "            for s in scales:\n",
    "                th = max(min_size, int(h * s // model.DIVIDABLE_BY * model.DIVIDABLE_BY))\n",
    "                tw = max(min_size, int(w * s // model.DIVIDABLE_BY * model.DIVIDABLE_BY))  # round off\n",
    "\n",
    "                scaled_x = F.interpolate(x, size=(th, tw), mode='bilinear', align_corners=True)\n",
    "                feat = model.extract_feat(scaled_x)\n",
    "                feat = feat.cpu().numpy()\n",
    "                feat_blend += feat\n",
    "\n",
    "        feats.append(feat_blend)\n",
    "        ids.extend(img_id)\n",
    "\n",
    "    feats = np.concatenate(feats) / len(scales)\n",
    "\n",
    "    output_path = Path(f'{exp_path}feats_{split}_{file_suffix}')\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(output_path / f'block{block_id}.h5', 'a') as f:\n",
    "        f.create_dataset('ids', data=np.array(ids, dtype=f'S{len(ids[0])}'))\n",
    "        f.create_dataset('feats', data=feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:50:15.147626Z",
     "start_time": "2019-11-03T08:50:15.141678Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/landmark/experiments/deep-image-retrieval/')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'\n",
    "\n",
    "from dirtorch.utils import common\n",
    "import dirtorch.nets as nets\n",
    "from src.eval_retrieval import eval_datasets\n",
    "\n",
    "def load_model(path, iscuda):\n",
    "    checkpoint = common.load_checkpoint(path, iscuda)\n",
    "    net = nets.create_model(pretrained=\"\", **checkpoint['model_options'])\n",
    "    net = common.switch_model_to_cuda(net, iscuda, checkpoint)\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "    net.preprocess = checkpoint.get('preprocess', net.preprocess)\n",
    "    if 'pca' in checkpoint:\n",
    "        net.pca = checkpoint.get('pca')\n",
    "    return net\n",
    "\n",
    "model = load_model('../experiments/Resnet101-AP-GeM-LM18.pt', True)\n",
    "model = model.module.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T09:08:35.504034Z",
     "start_time": "2019-11-03T08:50:48.708908Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "roxford5k: 100%|███| 4993/4993 [07:47<00:00, 10.90it/s]\n",
      "roxford5k: 100%|███████| 70/70 [00:04<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> roxford5k: mAP E: 82.03, M: 65.77, H: 40.87\n",
      ">> roxford5k: mP@k[1, 5, 10] E: [92.65 87.65 86.59], M: [92.86 87.71 82.43], H: [81.43 66.29 54.14]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rparis6k: 100%|████| 6322/6322 [09:46<00:00, 11.28it/s]\n",
      "rparis6k: 100%|████████| 70/70 [00:04<00:00, 15.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> rparis6k: mAP E: 92.52, M: 81.2, H: 61.62\n",
      ">> rparis6k: mP@k[1, 5, 10] E: [98.57 96.86 95.67], M: [100.    98.    97.57], H: [97.14 92.57 91.  ]\n"
     ]
    }
   ],
   "source": [
    "datasets = ('roxford5k', 'rparis6k')\n",
    "results = eval_datasets(model, datasets=datasets, ms=True, tta_gem_p=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T09:23:05.479937Z",
     "start_time": "2019-11-03T09:23:03.776729Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/landmark/experiments/deep-image-retrieval/')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '4,5'\n",
    "\n",
    "from dirtorch.utils import common\n",
    "import dirtorch.nets as nets\n",
    "from src.eval_retrieval import eval_datasets\n",
    "\n",
    "def load_model(path, iscuda):\n",
    "    checkpoint = common.load_checkpoint(path, iscuda)\n",
    "    net = nets.create_model(pretrained=\"\", **checkpoint['model_options'])\n",
    "    net = common.switch_model_to_cuda(net, iscuda, checkpoint)\n",
    "    net.load_state_dict(checkpoint['state_dict'])\n",
    "    net.preprocess = checkpoint.get('preprocess', net.preprocess)\n",
    "    if 'pca' in checkpoint:\n",
    "        net.pca = checkpoint.get('pca')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import utils, data_utils, metrics\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "# import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "\n",
    "ROOT = '/opt/landmark/'\n",
    "params = {\n",
    "    'ex_name': 'eval_ap',\n",
    "    'test_batch_size': 16,\n",
    "    'fc_dim': 2048,\n",
    "}\n",
    "splits = ['test19', 'index19']\n",
    "scale = 'L2'\n",
    "ms = True\n",
    "n_blocks = 1\n",
    "block_id = 0\n",
    "\n",
    "train_transform, eval_transform = data_utils.build_transforms()\n",
    "\n",
    "data_loaders = data_utils.make_predict_loaders(params,\n",
    "                                               eval_transform=eval_transform,\n",
    "                                               scale=scale,\n",
    "                                               splits=splits,\n",
    "                                               num_workers=8,\n",
    "                                               n_blocks=n_blocks,\n",
    "                                               block_id=block_id)\n",
    "\n",
    "model_path = ROOT + 'experiments/Resnet101-AP-GeM-LM18.pt'\n",
    "exp_path = ROOT + f'experiments/{params[\"ex_name\"]}/'\n",
    "if not Path(exp_path).exists():\n",
    "    Path(exp_path).mkdir(parents=True)\n",
    "\n",
    "model = load_model(model_path, True)\n",
    "model = model.module.eval()\n",
    "\n",
    "file_suffix = model_path.split('/')[-1].replace('.pth', '')\n",
    "file_suffix = scale + '_' + file_suffix\n",
    "file_suffix = 'ms_' + file_suffix if ms else file_suffix\n",
    "\n",
    "min_size = 128\n",
    "scales = [0.75, 1.0, 1.25] if ms else [1.0]\n",
    "\n",
    "for split in splits:\n",
    "    ids, feats = [], []\n",
    "    for i, (img_id, x) in tqdm(enumerate(data_loaders[split]),\n",
    "                               total=len(data_loaders[split]),\n",
    "                               miniters=None, ncols=55):\n",
    "\n",
    "        batch_size, _, h, w = x.shape\n",
    "        feat_blend = np.zeros((batch_size, params['fc_dim']), dtype=np.float32)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = x.to('cuda')\n",
    "\n",
    "            for s in scales:\n",
    "                th = max(min_size, int(h * s // model.DIVIDABLE_BY * model.DIVIDABLE_BY))\n",
    "                tw = max(min_size, int(w * s // model.DIVIDABLE_BY * model.DIVIDABLE_BY))  # round off\n",
    "\n",
    "                scaled_x = F.interpolate(x, size=(th, tw), mode='bilinear', align_corners=True)\n",
    "                feat = model.extract_feat(scaled_x)\n",
    "                feat = feat.cpu().numpy()\n",
    "                feat_blend += feat\n",
    "\n",
    "        feats.append(feat_blend)\n",
    "        ids.extend(img_id)\n",
    "\n",
    "    feats = np.concatenate(feats) / len(scales)\n",
    "\n",
    "    output_path = Path(f'{exp_path}feats_{split}_{file_suffix}')\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    with h5py.File(output_path / f'block{block_id}.h5', 'a') as f:\n",
    "        f.create_dataset('ids', data=np.array(ids, dtype=f'S{len(ids[0])}'))\n",
    "        f.create_dataset('feats', data=feats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-03T08:50:41.523554Z",
     "start_time": "2019-11-03T08:50:41.314877Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand((1, 3, 256, 256)).cuda()\n",
    "y = model(x.cuda())\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-04T05:22:56.956565Z",
     "start_time": "2019-11-04T05:21:48.941420Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build index...\n",
      "query search done.\n",
      "saved to ../output/AP_Loss.csv.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "from collections import Counter\n",
    "import faiss\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "from src import utils\n",
    "from src.reranking import Diffusion, explore_exploit\n",
    "# from experiments.submit_retrieval import predict_landmark_id\n",
    "\n",
    "ROOT = '../'\n",
    "\n",
    "setting = 'AP_Loss'\n",
    "index_dirs = ['../experiments/eval_ap/feats_index19_ms_L2_Resnet101-AP-GeM-LM18.pt/']\n",
    "test_dirs = ['../experiments/eval_ap/feats_test19_ms_L2_Resnet101-AP-GeM-LM18.pt/']\n",
    "# index_dirs = ['../experiments/eval_triplet/feats_index19_ms_L2_gl18-tl-resnet101-gem-w-a4d43db/']\n",
    "# test_dirs = ['../experiments/eval_triplet/feats_test19_ms_L2_gl18-tl-resnet101-gem-w-a4d43db/']\n",
    "\n",
    "weights = [1.0]\n",
    "\n",
    "ids_index, feats_index = utils.prepare_ids_and_feats(index_dirs, weights, normalize=True)\n",
    "ids_test, feats_test = utils.prepare_ids_and_feats(test_dirs, weights, normalize=True)\n",
    "\n",
    "co = faiss.GpuMultipleClonerOptions()\n",
    "co.shard = True\n",
    "\n",
    "vres = []\n",
    "for _ in range(2):\n",
    "    res = faiss.StandardGpuResources()\n",
    "    vres.append(res)\n",
    "\n",
    "print('build index...')\n",
    "cpu_index = faiss.IndexFlatIP(feats_index.shape[1])\n",
    "gpu_index = faiss.index_cpu_to_gpu_multiple_py(vres, cpu_index, co)\n",
    "gpu_index.add(feats_index)\n",
    "sims, topk_idx = gpu_index.search(x=feats_test, k=100)\n",
    "print('query search done.')\n",
    "\n",
    "subm = pd.DataFrame(ids_test, columns=['id'])\n",
    "subm['images'] = np.apply_along_axis(' '.join, axis=1, arr=ids_index[topk_idx])\n",
    "\n",
    "output_name = f'../output/{setting}.csv.gz'\n",
    "subm[['id', 'images']].to_csv(output_name, compression='gzip', index=False)\n",
    "print('saved to ' + output_name)\n",
    "\n",
    "cmd = f'kaggle c submit -c landmark-retrieval-2019 -f {output_name} -m \"\" '\n",
    "print(cmd)\n",
    "subprocess.run(cmd, shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
